{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33073c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from globals import *\n",
    "from cpfunctions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4049d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read file.\n",
    "df = pd.read_csv(FILE_PATH)\n",
    "\n",
    "# Encode labels into integers.\n",
    "le = LabelEncoder()\n",
    "df[\"label\"] = le.fit_transform(df[\"label\"])\n",
    "\n",
    "# Get features, userid, and class\n",
    "y = df[\"label\"]\n",
    "\n",
    "# Drop the label. We also drop userid since it is not needed for the mixed model.\n",
    "X = df.drop([\"label\",\"userid\"], axis = 1)\n",
    "\n",
    "# Save classes order.\n",
    "save_classes_order(pd.DataFrame(le.classes_), DATASET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff576fa1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Arrays to store results.\n",
    "it = []\n",
    "method = []\n",
    "groundTruth = []\n",
    "prediction = []\n",
    "predictionSet = []\n",
    "scores = [] # prediction scores as produced by the underlying model.\n",
    "pvalues = []\n",
    "\n",
    "for i in range(ITERATIONS):\n",
    "\n",
    "    curr_it = 1 + i # current iteration.\n",
    "    \n",
    "    print(\"Iteration \" + str(curr_it))\n",
    "\n",
    "    # Set random seed. This should be updated based on iteration number.\n",
    "    random_seed = 100 + curr_it\n",
    "\n",
    "    # Split into train, calibration, and test sets.\n",
    "    X_train, X_rest, y_train, y_rest = train_test_split(X, y,\n",
    "                                                        train_size = PCT_TRAIN, \n",
    "                                                        stratify = y, \n",
    "                                                        random_state = random_seed)\n",
    "\n",
    "    X_calib, X_test, y_calib, y_test = train_test_split(X_rest, y_rest,\n",
    "                                                        train_size = PCT_CALIBRATION,\n",
    "                                                        stratify = y_rest,\n",
    "                                                        random_state = random_seed)\n",
    "\n",
    "    # Normalize data.\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_calib = scaler.transform(X_calib)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "    # Fit the models\n",
    "    classifiers = fit_models(X_train, y_train, random_seed)\n",
    "    \n",
    "    # Build the conformal models.\n",
    "    for model in classifiers:\n",
    "        cp = MapieClassifier(estimator=model[1],\n",
    "                               cv=\"prefit\",\n",
    "                               method=\"score\",\n",
    "                               random_state=random_seed)\n",
    "\n",
    "        cp.fit(X_calib, y_calib)\n",
    "\n",
    "        y_pred, y_set = cp.predict(X_test, alpha=ALPHA)\n",
    "\n",
    "        y_set = np.squeeze(y_set)\n",
    "\n",
    "        #### Append results ####\n",
    "        n = len(y_pred)\n",
    "\n",
    "        # Iteration\n",
    "        tmp = np.empty(n, dtype=int)\n",
    "        tmp.fill(curr_it)\n",
    "        it.extend(tmp)\n",
    "\n",
    "        # Method name\n",
    "        method.extend([model[0]] * n)\n",
    "\n",
    "        # Ground truth\n",
    "        groundTruth.extend(le.inverse_transform(y_test))\n",
    "\n",
    "        # Prediction\n",
    "        prediction.extend(le.inverse_transform(y_pred))\n",
    "\n",
    "        # Prediction set.\n",
    "        predictionSet.extend([\"|\".join(le.classes_[y_set[i]]) for i in range(n)])\n",
    "\n",
    "        # Predicted scores.\n",
    "        pred_scores = model[1].predict_proba(X_test)\n",
    "        scores.extend([\"|\".join(pred_scores[i,y_set[i]].astype(str)) for i in range(n)])\n",
    "        \n",
    "        # Compute p-values.\n",
    "        cal_probs = model[1].predict_proba(X_calib)\n",
    "        prob_true_class = cal_probs[np.arange(len(X_calib)),y_calib]\n",
    "        calib_scores = 1 - prob_true_class\n",
    "        test_scores = 1 - pred_scores\n",
    "        arr_pvalues = compute_pvalues(calib_scores, test_scores)\n",
    "        pvalues.extend([\"|\".join(arr_pvalues[i,:].astype(str)) for i in range(n)])\n",
    "\n",
    "# Store results in data frame.\n",
    "d = {'it': it, 'method': method, \n",
    "     'groundTruth': groundTruth,\n",
    "     'prediction': prediction,\n",
    "     'predictionSet': predictionSet,\n",
    "     'scores': scores,\n",
    "     'pvalues': pvalues}\n",
    "\n",
    "results = pd.DataFrame(d)\n",
    "\n",
    "save_df(results, DATASET_PATH, \"mixed\", \"results.csv\")\n",
    "\n",
    "# Create general results dir.\n",
    "create_results_dir(DATASET_PATH)\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ad81bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

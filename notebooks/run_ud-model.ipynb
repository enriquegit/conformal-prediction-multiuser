{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624ea108",
   "metadata": {},
   "outputs": [],
   "source": [
    "from globals import *\n",
    "from cpfunctions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc9f708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read file.\n",
    "df = pd.read_csv(FILE_PATH)\n",
    "\n",
    "# Encode labels into integers.\n",
    "le = LabelEncoder()\n",
    "df[\"label\"] = le.fit_transform(df[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdaa60a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_users = np.unique(df[\"userid\"])\n",
    "\n",
    "# Arrays to store results.\n",
    "it = []\n",
    "userid = []\n",
    "method = []\n",
    "groundTruth = []\n",
    "prediction = []\n",
    "predictionSet = []\n",
    "scores = [] # prediction scores as produced by the underlying model.\n",
    "pvalues = []\n",
    "\n",
    "for i in range(ITERATIONS):\n",
    "\n",
    "    curr_it = 1 + i # current iteration.\n",
    "    \n",
    "    print(\"Iteration \" + str(curr_it))\n",
    "\n",
    "    # Set random seed. This should be updated based on iteration number.\n",
    "    random_seed = 100 + curr_it\n",
    "\n",
    "    for u in unique_users:\n",
    "        \n",
    "        tmp = df[df[\"userid\"]==u]\n",
    "        \n",
    "        # Get features, and class\n",
    "        y = tmp[\"label\"]\n",
    "        X = tmp.drop([\"label\",\"userid\"], axis = 1)\n",
    "        \n",
    "        # Split into train, calibration, and test sets.\n",
    "        X_train, X_rest, y_train, y_rest = train_test_split(X, y,\n",
    "                                                            train_size = PCT_TRAIN, \n",
    "                                                            stratify = y, \n",
    "                                                            random_state = random_seed)\n",
    "        \n",
    "        \n",
    "        X_calib, X_test, y_calib, y_test = train_test_split(X_rest, y_rest,\n",
    "                                                            train_size = PCT_CALIBRATION,\n",
    "                                                            stratify = y_rest,\n",
    "                                                            random_state = random_seed)\n",
    "\n",
    "        # Normalize data.\n",
    "        scaler = MinMaxScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_calib = scaler.transform(X_calib)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        \n",
    "        # Fit the models\n",
    "        classifiers = fit_models(X_train, y_train, random_seed)\n",
    "        \n",
    "        # Build the conformal models.\n",
    "        for model in classifiers:\n",
    "            cp = MapieClassifier(estimator=model[1],\n",
    "                                   cv=\"prefit\",\n",
    "                                   method=\"score\",\n",
    "                                   random_state=random_seed)\n",
    "\n",
    "            cp.fit(X_calib, y_calib)\n",
    "\n",
    "            y_pred, y_set = cp.predict(X_test, alpha=ALPHA)\n",
    "\n",
    "            y_set = np.squeeze(y_set)\n",
    "\n",
    "            #### Append results ####\n",
    "            n = len(y_pred)\n",
    "\n",
    "            # Iteration\n",
    "            tmp = np.empty(n, dtype=int)\n",
    "            tmp.fill(curr_it)\n",
    "            it.extend(tmp)\n",
    "            \n",
    "            # User id\n",
    "            tmp = np.empty(n, dtype=int)\n",
    "            tmp.fill(u)\n",
    "            userid.extend(tmp)\n",
    "\n",
    "            # Method name\n",
    "            method.extend([model[0]] * n)\n",
    "\n",
    "            # Ground truth\n",
    "            groundTruth.extend(le.inverse_transform(y_test))\n",
    "\n",
    "            # Prediction\n",
    "            prediction.extend(le.inverse_transform(y_pred))\n",
    "\n",
    "            # Prediction set.\n",
    "            predictionSet.extend([\"|\".join(le.classes_[y_set[i]]) for i in range(n)])\n",
    "\n",
    "            # Predicted scores.\n",
    "            pred_scores = model[1].predict_proba(X_test)\n",
    "            scores.extend([\"|\".join(pred_scores[i,y_set[i]].astype(str)) for i in range(n)])\n",
    "            \n",
    "            # Compute p-values.\n",
    "            cal_probs = model[1].predict_proba(X_calib)\n",
    "            prob_true_class = cal_probs[np.arange(len(X_calib)),y_calib]\n",
    "            calib_scores = 1 - prob_true_class\n",
    "            test_scores = 1 - pred_scores\n",
    "            arr_pvalues = compute_pvalues(calib_scores, test_scores)\n",
    "            pvalues.extend([\"|\".join(arr_pvalues[i,:].astype(str)) for i in range(n)])\n",
    "            \n",
    "# Store results in data frame.\n",
    "d = {'it': it,\n",
    "     'userid': userid,\n",
    "     'method': method,\n",
    "     'groundTruth': groundTruth,\n",
    "     'prediction': prediction,\n",
    "     'predictionSet': predictionSet,\n",
    "     'scores': scores,\n",
    "     'pvalues': pvalues}\n",
    "\n",
    "results = pd.DataFrame(d)\n",
    "\n",
    "save_df(results, DATASET_PATH, \"ud\", \"results.csv\")\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6119231d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
